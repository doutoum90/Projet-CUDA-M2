<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <meta name="author" content="Mathias DIDIER">
  <link rel="shortcut icon" href="../favicon.ico">
  
  <title>Optimisation/Reduction - Développement d’applications sous processeur graphique (GPU / CUDA).</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../css/highlight.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Optimisation/Reduction";
    var mkdocs_page_input_path = "reduction.md";
    var mkdocs_page_url = "/reduction/";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js"></script>
  <script src="../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../js/highlight.pack.js"></script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> Développement d’applications sous processeur graphique (GPU / CUDA).</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="..">Home</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../introduction/">Introduction</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../tk1/">Jetson TK1</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../connexions/">Connexions</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../cpu_gpu/">CPU/GPU</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../architecture/">Architectures</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../cuda/">CUDA</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../frameworks/">Frameworks</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../tensorflow/">Tensorflow</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../applications/">Applications</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../traitementImage/">Traitement d'image</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../optimisation/">Optimisation GPU</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 current">
        <a class="current" href="./">Optimisation/Reduction</a>
        
            <ul>
            
                <li class="toctree-l3"><a href="#optimisation-dune-reduction-parallele-en-cuda">Optimisation d'une Reduction Parallèle en CUDA</a></li>
                
                    <li><a class="toctree-l4" href="#reduction-1-adressage-a-intervalle">Reduction 1 : Adressage à intervalle</a></li>
                
                    <li><a class="toctree-l4" href="#reduction-2-kernel">Reduction 2 : Kernel</a></li>
                
                    <li><a class="toctree-l4" href="#reduction-3-adressement-sequentiel">Reduction 3 : Adressement Séquentiel</a></li>
                
            
            </ul>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../signRecognition/">Reconnaissance des signes</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../ressources/">Ressources</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../outils/">Outils</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../about/">About</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../sceances/">Scéances</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../installations/">Installations</a>
        
    </li>
<li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">Développement d’applications sous processeur graphique (GPU / CUDA).</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>Optimisation/Reduction</li>
    <li class="wy-breadcrumbs-aside">
      
        <a href="https://github.com/matEhickey/Projet-CUDA-M2/edit/master/docs/reduction.md"
          class="icon icon-github"> Edit on GitHub</a>
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="optimisation-dune-reduction-parallele-en-cuda">Optimisation d'une Reduction Parallèle en CUDA</h1>
<p>La reduction parrallèle consiste à assembler chaque élément d'un tableau afin de n'obtenir qu'un élément final représentant ce tableau (pour un tableau d'entier il s'agit d'une somme).</p>
<p>Nous allons ici nous servir d'une reduction parallèle d'un tableau comme exemple d'optimisation, un exemple classique dans la littérature concernant l'optimisation en CUDA, car cette réduction est facile à implémenter.
Une réduction contient du parallèlisme mais est difficile à exploiter car plus les calculs progressent et moins il y a de parallélisme, et il y beaucoup d'accès aux données et de calculs. 
La réduction est difficile de l'optimiser au maximun mais il est possible de découper cette optimisation étape par étape.</p>
<p>L'implémentation se feras ici avec un tableau de taille conséquante afin de pouvoir comparer les différents niveaux d'optimisation et afin de pouvoir utiliser les mécaniques de blocs de CUDA.
De plus en utilisant une taille de tableau assez grande pour occuper la totalité des threads disponibles pour notre device, nous pouvons facilement observer les gains de performances causés par une diminution de threads peu voir non actifs.</p>
<h2 id="reduction-1-adressage-a-intervalle">Reduction 1 : Adressage à intervalle</h2>
<p>Une approche de la réduction parrallèle consiste à utiliser un arbre : </p>
<p><img alt="" src="../img/tree.png" />   </p>
<p>Afin d'implémenter cette répresentation nous allons devoir utiliser plusieurs blocs, chacun réduisant une partie du tableau.
Quel choix effectuer pour la communication des résulatts entre les diffrents blocs ? 
En synchronisant tout les threads de tout les blocs il serait facile de communiquer les résultats, il nous suffirait d'effectuer la reduction de manière recursive dans chaque blocs jusqu'à atteindr eun résultat unique à partager.</p>
<h3 id="probleme-comment-effectuer-une-synchronisation-globale">Problème : comment effectuer une synchronisation globale</h3>
<p>CUDA n'implémente pas de synchronisation globale pour deux raisons :
    - Pour éviter un certains nobmre de deadlocks possibles.
    - Car cela côute cher à créer au niveau hardware lorsque que le nombre de processeur est grand.</p>
<p>Nous allons donc devoir décomposer notre fonction en de multiples kernels en utilisant un premier thread comme point de synchronisation global.
Dans notre cas, celui d'une réduction, nous pouvons utiliser le même code pour chaque kenerl, notre invocation de kernel est donc récursive.</p>
<p><img alt="" src="../img/kernels.png" />    </p>
<p>Exemple d'un kernel basique de réduction </p>
<pre><code>
//g_idata est l'output et g_idata est l'input
__global__ void reduce0(int *g_idata, int *g_odata, int size){

    //vecteur de sortie partagé avec tout les threads dans un bloc
    extern __shared__ int sdata[];

    //On recupere l'endroit ou l'on ecrit dans la memoire partagé (tid) ainsi que la case que nous allons traiter (i)
    unsigned int tid = threadIdx.x;
    unsigned int i = blockIdx.x*blockDim.x + threadIdx.x;
    //Dans la cas où nous ne sommes pas dans le tableau nous renvoyons 0
    sdata[tid] = 0;
    if (i&lt;size)
        sdata[tid] = g_idata[i];

    //__syncthreads permet de synchroniser tout les threads afin 
    __syncthreads();

    for (unsigned int s = 1; s &lt; blockDim.x; s *= 2) {
        if (tid % (2 * s) == 0) {

            sdata[tid] += sdata[tid + s];

        }
        __syncthreads();
    }

    //On écrit le résultat de ce bloc en mémoire globale
    if (tid == 0) g_odata[blockIdx.x] = sdata[0];
}

</code></pre>

<p><img alt="" src="../img/interval.png" />   </p>
<p>Exemple d'appel de ce kernel de manière récursive :</p>
<pre><code>
//Nous passons notre kenerl en paramètre à notre fonction de benchmarking ainsi que la taille du vecteur à réduire
void benchmark(int size, void(*fptr)(int*, int*, int)){
    //Le nombre de threads par blocs que nous allons utiliser
    int threadsPerBlock = 1024;
    //Le nombre totals de blocs que nous devons utiliser afin de réduire l'entiéreté du vecteur
    int totalBlocks = (size + (threadsPerBlock - 1)) / threadsPerBlock;

    //Utilisation de la librairie thrust afin de créeer facilement des vecteurs host et devices permettant le transfert des données d'input et d'ouput (cf doc)
    thrust::host_vector&lt;int&gt; data_h_i(size, 1);
    thrust::device_vector&lt;int&gt; data_v_i = data_h_i;
    thrust::device_vector&lt;int&gt; data_v_o(totalBlocks);
    thrust::device_vector&lt;int&gt; data_v_o_final(totalBlocks / threadsPerBlock);

    int* output = thrust::raw_pointer_cast(data_v_o.data());
    int* input = thrust::raw_pointer_cast(data_v_i.data());
    int* ouput_f = thrust::raw_pointer_cast(data_v_o_final.data());

    //Invocation du kernel

    fptr &lt;&lt;&lt;totalBlocks, threadsPerBlock, threadsPerBlock*sizeof(int) &gt;&gt;&gt;(input, output, size);
    if (totalBlocks / threadsPerBlock &gt; 1){
        //Après le premier appel si nous utilisons plus de threads que disponible dans un seul bloc, nous devons rappeler le kernel afin de réduire notre vecteur de résultat
        fptr &lt;&lt; &lt;totalBlocks / threadsPerBlock, threadsPerBlock, threadsPerBlock*sizeof(int) &gt;&gt; &gt;(output, ouput_f, totalBlocks);

        fptr &lt;&lt; &lt;1, totalBlocks / threadsPerBlock, threadsPerBlock*sizeof(int) &gt;&gt; &gt;(ouput_f, input, totalBlocks);
    }
    else{
        fptr &lt;&lt; &lt;1, threadsPerBlock, threadsPerBlock*sizeof(int) &gt;&gt; &gt;(output, input, totalBlocks);
    }

    //Nous attendons la fin de l'éxecution de chaque bloc, les kernels n'étant pas bloquant pour le CPU
    cudaDeviceSynchronize();

    //Traitement des résultats
    data_v_o[0] = data_v_i[0];
    data_v_i.clear();
    data_v_i.shrink_to_fit();

    thrust::host_vector&lt;int&gt; data_h_o = data_v_o;

    data_v_o.clear();
    data_v_o.shrink_to_fit();

    cout &lt;&lt; &quot;Somme : &quot; &lt;&lt; data_h_o[0] &lt;&lt; endl;
}

</code></pre>

<h3 id="probleme-branchement-divergents">Problème : branchement divergents</h3>
<p>Rappel : Les threads d'un bloc sont regroupés en warps de taille fixe pour l'exécution sur un noyau CUDA, et les threads dans un warp doivent suivre la même trajectoire d'exécution. Tous les threads doivent exécuter la même instruction en même temps. En d'autres termes, les threads ne peuvent pas diverger.</p>
<h2 id="reduction-2-kernel">Reduction 2 : Kernel</h2>
<pre><code>
//g_idata est l'output et g_idata est l'input
__global__ void reduce1(int *g_idata, int *g_odata, int size){

    //vecteur de sortie partagé avec tout les threads dans un bloc
    extern __shared__ int sdata[];

    //On recupere l'endroit ou l'on ecrit dans la memoire partagé (tid) ainsi que la case que nous allons traiter (i)
    unsigned int tid = threadIdx.x;
    unsigned int i = blockIdx.x*blockDim.x + threadIdx.x;
    //Dans la cas où nous ne sommes pas dans le tableau nous renvoyons 0
    sdata[tid] = 0;
    if (i&lt;size)
        sdata[tid] = g_idata[i];

    //__syncthreads permet de synchroniser tout les threads afin 
    __syncthreads();

    for (unsigned int s = 1; s &lt; blockDim.x; s *= 2) {
        int index = 2 * s * tid;

        if (index &lt; blockDim.x){
            sdata[index] += sdata[index + s];
        }
        __syncthreads();
    }


    //On écrit le résultat de ce bloc en mémoire globale
    if (tid == 0) g_odata[blockIdx.x] = sdata[0];
}

</code></pre>

<h3 id="probleme-conflit-des-bancs-de-memoires-partagees">Problème : Conflit des bancs de mémoires partagées</h3>
<h2 id="reduction-3-adressement-sequentiel">Reduction 3 : Adressement Séquentiel</h2>
<p>Nous remplacons l'index strided de la boucle par une boucle inversé et un index basé sur l'id des threads.</p>
<pre><code>

    for (unsigned int s =blockDim.x / 2; s&gt;0; s &gt;&gt;= 1) {
        if(tid &lt; s) {
            sdata[tid] += sdata[tid + s];
        }
        __syncthreads();
    }


</code></pre>

<p><img alt="" src="../img/sequential.png" /> </p>
<h3 id="probleme-threads-inactifs">Problème : Threads inactifs</h3>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../signRecognition/" class="btn btn-neutral float-right" title="Reconnaissance des signes">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../optimisation/" class="btn btn-neutral" title="Optimisation GPU"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
	  
        </div>
      </div>

    </section>
    
  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
          <a href="https://github.com/matEhickey/Projet-CUDA-M2" class="icon icon-github" style="float: left; color: #fcfcfc"> GitHub</a>
      
      
        <span><a href="../optimisation/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../signRecognition/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script src="../js/theme.js"></script>

</body>
</html>
