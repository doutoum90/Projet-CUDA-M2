<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <meta name="author" content="Mathias DIDIER">
  <link rel="shortcut icon" href="../favicon.ico">
  
  <title>Frameworks - Développement d’applications sous processeur graphique (GPU / CUDA).</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../css/highlight.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Frameworks";
    var mkdocs_page_input_path = "frameworks.md";
    var mkdocs_page_url = "/frameworks/";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js"></script>
  <script src="../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../js/highlight.pack.js"></script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> Développement d’applications sous processeur graphique (GPU / CUDA).</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="..">Home</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../introduction/">Introduction</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../tk1/">Jetson TK1</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../connexions/">Connexions</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../cpu_gpu/">CPU/GPU</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../architecture/">Architectures</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../cuda/">CUDA</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 current">
        <a class="current" href="./">Frameworks</a>
        
            <ul>
            
                <li class="toctree-l3"><a href="#frameworks">Frameworks</a></li>
                
                    <li><a class="toctree-l4" href="#bindings">Bindings</a></li>
                
                    <li><a class="toctree-l4" href="#librairies">Librairies</a></li>
                
                    <li><a class="toctree-l4" href="#frameworks_1">Frameworks</a></li>
                
                    <li><a class="toctree-l4" href="#see-also">See Also</a></li>
                
            
            </ul>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../tensorflow/">Tensorflow</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../applications/">Applications</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../traitementImage/">Traitement d'image</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../optimisation/">Optimisation GPU</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../reduction/">Optimisation/Reduction</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../signRecognition/">Reconnaissance des signes</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../ressources/">Ressources</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../outils/">Outils</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../about/">About</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../sceances/">Scéances</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../installations/">Installations</a>
        
    </li>
<li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">Développement d’applications sous processeur graphique (GPU / CUDA).</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>Frameworks</li>
    <li class="wy-breadcrumbs-aside">
      
        <a href="https://github.com/matEhickey/Projet-CUDA-M2/edit/master/docs/frameworks.md"
          class="icon icon-github"> Edit on GitHub</a>
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="frameworks">Frameworks</h1>
<p>Il existe de nombreux langages , librairies et frameworks avec lequels on peut utiliser la puissance des GPU en fonction de ses besoins.</p>
<hr />
<h2 id="bindings">Bindings</h2>
<h3 id="cuda-c">CUDA C</h3>
<p>Librairies bas niveau pour l'utilisation des threads CUDA<br />
<a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/">CUDA C Programmming</a></p>
<h3 id="pycuda">PyCUDA</h3>
<p>Bindings Python pour les librairies CUDA. Permet d'integrer des kernels CUDA dans du code python<br />
<a href="https://mathema.tician.de/software/pycuda/">PyCUDA</a></p>
<hr />
<h2 id="librairies">Librairies</h2>
<h3 id="amgx">AmgX</h3>
<p>Resolveur de problèmes utilisé pour les simulations physique nottament, dans les domaines de l'industrie.<br />
<a href="https://developer.nvidia.com/amgx">AmgX</a></p>
<h3 id="cudnn">CuDNN</h3>
<p>Librairies d'implémentations de réseau neuronnaux de type Deep-Leearning.
Peut être utilisé pour accélerer le travail d'autre frameworks de machine learning tel que Caffe, Tensorflow, Theano, Torch, CNTK etc..<br />
<a href="https://developer.nvidia.com/deep-learning-frameworks">Compatibles</a><br />
<a href="https://developer.nvidia.com/cuDNN">CuDNN</a></p>
<h3 id="cufft">CuFFT</h3>
<p>Transformation de Fourrier rapide via GPU<br />
<a href="https://developer.nvidia.com/cuFFT">CuFFT</a></p>
<h3 id="index">IndeX</h3>
<p>Visualisation de données météorologiques.<br />
<a href="https://developer.nvidia.com/index">Index</a></p>
<h3 id="nvgraph">NvGRAPH</h3>
<p>Librairies regroupant des algorythmes d'analyse et traitements de graphes contenant plus de 2 milliars d'arretes.<br />
<a href="https://developer.nvidia.com/nvGRAPH">Index</a></p>
<h3 id="cuda-maths-library">CUDA Maths library</h3>
<p>Ensemble de fonctions mathématiques optimisé pour GPU<br />
[CUDA Maths library](https://developer.nvidia.com/cuda-math-library</p>
<h3 id="opencv">OpenCV</h3>
<p>Librairie Open Source de Vision par ordinateur (Computer Vision), de traitement d'images, et de machine learning<br />
<a href="https://developer.nvidia.com/opencv">OpenCV</a></p>
<hr />
<h2 id="frameworks_1">Frameworks</h2>
<p>Nous avons étudié différents frameworks GPU pour déterminer nos besoins réels pour notre application finale.<br />
Notre choix se portait initialement sur Tensorflow, qui est le cador actuel dans le domaine de l'IA, et qui nous a été fortement conseillé, cependant nous voulions tester ses concurents pour justifier l'utilisation de Tensorflow.<br />
Pour la rapidité des différents essais, ainsi que la préservation du systeme, nous avons décidé d'utilisé la plateforme Docker, qui nous permet l'installation de mini-vm préconfiguré avec les logiciels nécessaire a nos besoins.<br />
Cependant, ces tests se faisant sur les heures personelles, nous utilisions docker, et non nvidia-docker qui ne fonctionne pas sur Windows, ainsi, l'utilisation des GPU n'était pas possible, de toute facon, le but étant de comparer les frameworks d'inteligence entre eux, les resultats de classifications (et la simplicité avec laquelle les programmes se codent) nous interessais plus que les temps d'éxecutions.<br />
Nous avons estimé, que notre probleme (transcription des signes), est assez proche du probleme de classification d'image mnist, qui consiste a classifier des chiffres écrit à la main.<br />
Exemples de code pour résoudre le probleme de classification de <a href="http://yann.lecun.com/exdb/mnist/">mnist</a></p>
<h3 id="caffe">Caffe</h3>
<p>Deep-learning framework, optimisé pour GPU<br />
<a href="http://caffe.berkeleyvision.org/">Caffe</a><br />
<a href="http://caffe.berkeleyvision.org/gathered/examples/mnist.html">mnist caffee</a><br />
<a href="https://hub.docker.com/r/kaixhin/caffe/">docker</a>  </p>
<h3 id="cntk">CNTK</h3>
<p>Microsoft cognitive Toolkit<br />
<a href="https://www.microsoft.com/en-us/research/product/cognitive-toolkit/">CNTK</a><br />
<a href="https://github.com/Microsoft/CNTK/blob/master/Examples/Image/Classification/MLP/MLP_MNIST.cntk">mnist cntk</a><br />
<a href="https://hub.docker.com/r/microsoft/cntk/">docker</a>  </p>
<h3 id="theano">Theano</h3>
<p>Librairie de calcul mathématiques, notamment multidimensions, optimisé pour les GPU.<br />
<a href="http://deeplearning.net/software/theano/">Theano</a><br />
<a href="https://github.com/lisa-lab/DeepLearningTutorials/blob/master/code/convolutional_mlp.py">mnist theano</a><br />
<a href="https://hub.docker.com/r/kaixhin/theano/">docker</a>  </p>
<h3 id="torch">Torch</h3>
<p>Framework à but scientifique qui supporte de nombreux algorythmes, en optimisant par GPU<br />
<a href="http://torch.ch/">Torch</a><br />
<a href="https://github.com/torch/demos/blob/master/train-a-digit-classifier/dataset-mnist.lua">mnist torch</a><br />
<a href="https://hub.docker.com/r/kaixhin/torch/">docker</a>  </p>
<h3 id="tensorflow">Tensorflow</h3>
<p>Tensorflow est le framework d'inteligence porté par Google, il semble le framework le plus complet, avec des tas de fonctionnalités et domaines d'application.<br />
La communauté est très active et de nombreuses ressources sont déja disponibles.<br />
Tensorflow est prévu pour le déployement sur de nombreux type de machines, comme les serveurs distribués, les ordinateurs personnels, ou encore les smartphones, que la machine dispose d'un GPU ou non.<br />
<a href="http://tensorflow.org">Tensorflow</a><br />
<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/mnist.py">mnist tensorflow</a><br />
<a href="https://hub.docker.com/r/tensorflow/tensorflow/">docker</a>  </p>
<h3 id="keras">Keras</h3>
<p>Keras est une surcouche utilisant ou Tensorflow, ou Theano, en simplifiant grandement l'écriture du code.<br />
En effet, le paradygmes par flow et tenseur est assez compliqué a imaginer, et encore plus à mettre en place.<br />
Avec Keras, la mise en place est simplifié au maximum, ne reste que les soucis de modélisation de notre problèmes.<br />
<a href="https://keras.io/">Keras</a><br />
<a href="https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py">mnist keras</a><br />
<img alt="sortie kerras mnist" src="../img/kerrasMnist.png" />
<a href="https://hub.docker.com/r/gw000/keras/">docker</a></p>
<h3 id="tflearn">Tflearn</h3>
<p>TFLearn fourni une interface à tensorflow de manière simplifé.<br />
Le code est beaucoup lisible, compréhensible, et est améliorable avec du vrai code Tensorflow au besoin.  </p>
<h3 id="opencv_1">OpenCV</h3>
<p>Après les résultats, plutot mauvais que nous ayons obtenu avec les classifiers d'images simples pour nos datasets d'images de mains, nous avons décider d'améliorer les images avec des pré-prétraitements, qui nous permettraient d'utiliser d'analyser des zones plus discriminantes de l'image, et avec des dimensions plus petites, ce qui devrait améliorer nos résultats, et les vitesses d'entrainements/de classification.<br />
Nous avons commencer par regarder les solutions que propose Nvidia (Nvidia Vision-works), mais nous avons trouvés des résultats comparatifs (Fichier a retrouver!!!)[.] et Vision-works est pour la majorité des problèmes plus lent que la version GPU de OpenCV, qui lui, est open-source, dispose d'une très large communauté, et possède des bindings dans de nombreux langages. 
On voit sur ce document que Nvidia-VisionWorks est surtout fait pour détecter des angles mouveant sur des flux vidéos.<br />
J'ai donc décidé d'essayer les versions C++, Java(via processing), et Python de OpenCV.<br />
Mon choix final se porte sur Python, car le groupe de projet maitrise bien ce langage, et que si nous utilisons Tensorflow, Tflearn, Keras etc, nous serions amener a le faire en Python.<br />
L'amélioration de la vitesse des traitements via la version C++ étant minime, je préfere l'écarter du au temps nécessaire pour développer.<br />
Enfin, la version Java était très bien, surtout grace processing, qui simplifie grandement la pratique de Java pour des applications graphiques, ainsi que par sa communauté.  </p>
<p>Ne distinguant aucune réelle différence dans les API en fonction du langage utilisé, j'ai décider pour définir le modèle des traitements en processing, car les modifications de codes et tests sont les plus rapides, et lorsque le modele nous semblera fonctionnel, de le porter sur Python.  </p>
<h2 id="see-also">See Also</h2>
<p><a href="https://developer.nvidia.com/gpu-accelerated-libraries">Liste de librairies accélérées par GPU</a><br />
<a href="https://developer.nvidia.com/deep-learning-frameworks">Liste de frameworks</a>
<a href="https://en.wikipedia.org/wiki/Comparison_of_deep_learning_software">Comparaison entre différents frameworks de Deep-Learning</a><br />
<a href="http://www.wangbo.info/img/mlmindmap.png">MindMap de différents modeles d'algorythmes de Machine-Learning</a><br />
<a href="http://tflearn.org/">TF Learn</a>  </p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../tensorflow/" class="btn btn-neutral float-right" title="Tensorflow">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../cuda/" class="btn btn-neutral" title="CUDA"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
	  
        </div>
      </div>

    </section>
    
  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
          <a href="https://github.com/matEhickey/Projet-CUDA-M2" class="icon icon-github" style="float: left; color: #fcfcfc"> GitHub</a>
      
      
        <span><a href="../cuda/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../tensorflow/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script src="../js/theme.js"></script>

</body>
</html>
